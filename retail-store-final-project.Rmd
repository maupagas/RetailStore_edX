---
title: "**Choose Your Own: Retail Store Final Project**"
subtitle: "[HarvardX Data Science Program Professional Certificate](https://www.edx.org/professional-certificate/harvardx-data-science)" 
author: "*Mauricio Pat√≥n*"
date: "*`r format(Sys.time(), '%B, %Y')`*"
output: 
  bookdown::pdf_document2:
    fig_caption: yes
    keep_tex: yes
    md_extensions: +footnotes
    number_sections: true
    toc: yes
  # pdf_document:
  #   number_sections: true
  #   df_print: paged
  #   toc: true  
  # html_document:
  #   number_sections: true
  #   df_print: paged
  #   toc: true
  #   toc_float: true

    # css: Mery_style.css
#   bookdown::html_document2:
#     fig_caption: yes
#     md_extensions: +footnotes
#     number_sections: true
#     toc: yes
#     toc_float: true
#     css: Mery_style.css
# bibliography: Yield_v_rate.bib
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, tidy=TRUE)

#Load All Required Packages
if(!require(ggplot2)) install.packages("ggplot2", repos = "http://cran.us.r-project.org")
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(tidyr)) install.packages("tidyr", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(tidyr)) install.packages("tidyr", repos = "http://cran.us.r-project.org")
if(!require(lubridate)) install.packages("lubridate", repos = "http://cran.us.r-project.org")
if(!require(Matrix)) install.packages("Matrix", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(scales)) install.packages("scales", repos = "http://cran.us.r-project.org")
if(!require(dummies)) install.packages("dummies", repos = "http://cran.us.r-project.org")
if(!require(FNN)) install.packages("FNN", repos = "http://cran.us.r-project.org")
if(!require(rpart)) install.packages("rpart", repos = "http://cran.us.r-project.org")
if(!require(rpart.plot)) install.packages("rpart.plot", repos = "http://cran.us.r-project.org")
if(!require(ipred)) install.packages("ipred", repos = "http://cran.us.r-project.org")
if(!require(gbm)) install.packages("gbm", repos = "http://cran.us.r-project.org")
if(!require(randomForest)) install.packages("randomForest", repos = "http://cran.us.r-project.org")
if(!require(nnet)) install.packages("nnet", repos = "http://cran.us.r-project.org")
if(!require(devtools)) install.packages("devtools", repos = "http://cran.us.r-project.org")
if(!require(kableExtra)) install.packages("kableExtra", repos = "http://cran.us.r-project.org")

# Load initial libraries
library(ggplot2)
library(tidyverse)
library(tidyr)
library(lubridate)
library(Matrix)
library(caret)
library(scales)

options(dplyr.summarise.inform = FALSE)

```

# **Final Report** 

## **Introduction** 

The Capstone Course of the [HarvardX Data Science Program Professional Certificate](https://www.edx.org/professional-certificate/harvardx-data-science) offered in [edX](https://www.edx.org/) requires, along with the MovieLens project a Choose Your Own Project. 

In this case, the student needs to select a database of his interest in order to perform a Machine Learning Project in which to predict a defined metric. 

For this work, a [Retail Shop dataset](https://www.kaggle.com/amark720/retail-shop-case-study-dataset) has been selected as the Case Study to work with. Identifying behaviors of customers could lead into marketing strategies that allow to link specific products to a particular target of customers. In addition, it is important for a store to obtain a rough estimate of their revenue based on the customers that might purchase items in the store.

A good model should provide a reasonably accurate prediction to the end-user. In order to measure the accuracy of a recommendation, different metrics can be used, such as the [Root Mean Squared Error](https://www.wikiwand.com/en/Root-mean-square_deviation#/References) (RMSE), the [Mean Squared Error](https://www.wikiwand.com/en/Mean_squared_error) (MSE). In this work, the RMSE will be the metric assigned to measure how close (or not) the estimation of how much a given user is going to spend.

\pagebreak

## **Methodology: Data Exploration and Preparation**

In this section, an exploration of the data is conducted. As previously stated, the data corresponding to a [Retail Shop dataset](https://www.kaggle.com/amark720/retail-shop-case-study-dataset) was downloaded. The data downloaded contains three csv files, one for customer information, one that contains information regarding the products categories and subcategories and another file that contains information regarding the transactions.

The files are loaded into R using the following code:

```{r loadData, echo = T}
# Load csv data for initial exploration
customer <- read.csv("https://raw.githubusercontent.com/maupagas/RetailStore_edX/main/retail-store-files/Customer.csv")
transactions <- read.csv("https://raw.githubusercontent.com/maupagas/RetailStore_edX/main/retail-store-files/Transactions.csv")
product_info <- read.csv("https://raw.githubusercontent.com/maupagas/RetailStore_edX/main/retail-store-files/prod_cat_info.csv")

```

### Preliminary data exploration

Once the data is loaded, the exploratory analysis can start. Before proceeding with any  modeling, the first step consists of understanding the data at hand. Therefore, the functions from the basic package *summary*, *str* and *head* were executed.

```{r explorationData, echo = T}
# Data Exploration
summary(product_info)
summary(customer)
summary(transactions)

head(transactions)

n_users <- n_distinct(transactions$cust_id)
n_transactions <- n_distinct(transactions$transaction_id)
```

An initial exploration reveals that there are `r n_users` users and `r n_transactions` transactions. From an initial exploratory analysis we observe that there are 6 categories of products and 12 subcategories. 

The date is also written as factors. Therefore some conversions are required to be able to make better use of the data.

Therefore, we will do the following:

* Convert the data to a datetime using the *lubridate* package.
* Convert categories and subcategories to factors.
* Convert the year of birth of the customer into age.
* Ensure that the columns have the same name in all variables.
* Fix missing values and NA's in the dataset.

```{r data-conversion}
# Convert time factors into date
date_1 <- as.Date(transactions$tran_date, "%d-%m-%Y")
date_2 <- as.Date(transactions$tran_date, "%d/%m/%Y")
transactions$tran_date <- ifelse(is.na(date_1), date_2, date_1)

# Fix the date into appropriate format
transactions$tran_date <- as.Date(transactions$tran_date, origin = "1970-01-01")

# Convert categories as factors in both variables
transactions$prod_subcat_code <- as.factor(transactions$prod_subcat_code)
transactions$prod_cat_code <- as.factor(transactions$prod_cat_code)

# Convert product into factors 
product_info$prod_sub_cat_code <- as.factor(product_info$prod_sub_cat_code) 
product_info$prod_cat_code <- as.factor(product_info$prod_cat_code)
```

Now, we are going to merge data between variables. For that, we need to make sure that all columns have the same name between dataframes.

```{r merge-data}
# Merge data 

# First, have the same column name for both variables
colnames(product_info)[3] <- "prod_subcat_code"
colnames(customer)[1] <- "cust_id"

# Once columns have the same name, we can join the data
transactions.new <- transactions %>% 
                            left_join(product_info, 
                                      by = c('prod_subcat_code',
                                             'prod_cat_code')) %>% 
                            left_join(customer, by = 'cust_id') %>% 
                            unite("prod_category", 
                                  c(prod_cat, prod_subcat),
                                  sep = " ", 
                                  remove = F) # Keep the original variables

# Obtain the age of the customer
transactions.new$cust_age <- year(transactions.new$tran_date) - 
                             year(as.Date(transactions.new$DOB, "%d-%m-%Y"))

```

Looking at the gender column, it appears that there are 9 customers of them do not belong to any gender. Therefore, this needs to be fixed. One option would be to eliminate those entries. The other option however, is to assign a gender based on the probability that the genders appear in the data base. The same occur for the city code. Two entries do not have a city code. We will sample randomly to fit the missing values

```{r gender-city-fix}
## Fix the Genders 
summary(transactions.new$Gender)
nonGender <- which(transactions.new$Gender == "" )

# Replace by sampling randomly according to the proportion in the sample
transactions.new$Gender[nonGender] <- sample(transactions.new$Gender, 
                                             length(nonGender), 
                                             replace = T)
transactions.new$Gender <- as.factor(transactions.new$Gender)

## Avoid having NA's in the variable city_code
nonCity <- which(is.na(transactions.new$city_code))
transactions.new$city_code[nonCity] <- sample(transactions.new$city_code, 
                                              length(nonCity), 
                                              replace = T)

```

Once all has been fixed, we can order the columns as we wish with the following code.

```{r, data-reorder}
# Now we can reorder the data properly...
transactions.ord <- transactions.new[ , c("cust_id", "DOB", "cust_age", "Gender", 
                                          "city_code", "transaction_id", "tran_date",
                                          "prod_subcat_code","prod_cat_code",
                                          "prod_category", "prod_cat", "prod_subcat",
                                          "Store_type", "Qty", "Rate", "Tax", "total_amt")]
```

We need also a dataset for future work that aggregates all the information _by customer_ instead of by transaction.

```{r, aggregate-data-customer}
## Aggregate also data by customers
cust.desc <- transactions.ord %>% filter(total_amt > 0) %>% 
  group_by(cust_id) %>%
  summarise(n = n(), 
            age = mean(cust_age), 
            city_code = mean(city_code), 
            Gender = Gender, 
            amount = sum(total_amt)) %>% 
            unique()
```

## **Methodology: Exploratory Graphs**

First, let's do some exploratory graphics to understand the transaction occurring in our retail store.

### Amount spent in the store

Let's see in Figure \@ref(fig:transactions-plots-all) how is the amount of money spent in the store:   

```{r transactions-plots-all, fig.cap = "Amount paid per transaction"}
# Distribution plot of ALL transactions
transactions %>% ggplot(aes(total_amt)) +
                        geom_histogram(bins = 20, color = "black", fill = "steelblue") + 
                        xlab("Amount paid") +
                        ylab("Number of transactions")
```
  


Figure \@ref(fig:transactions-plots-all) shows that the amount spent in returns is relatively low compared to the proportion that correspond to sales. We will ignore therefore for this project those products that consist of returns. Let's make a histogram then of only the sales by filtering the positive transactions. This can be seen in Figure \@ref(fig:transactions-plots-all).  


```{r transactions-plots-sales, fig.cap = "Amount paid per transaction"}
# Distribution plot of only sales
transactions %>% filter(total_amt > 0) %>%
                 ggplot(aes(total_amt)) + 
                 geom_histogram(bins = 20, color = "black", fill = "steelblue") +
                 xlab("Amount paid") +
                 ylab("Number of transactions") 


```
  

Figure \@ref(fig:transactions-plots-all) shows that most of the majority of the transactions correspond to expenditures of less than 2000 $. However, there are a small number of transactions that are over 6000 dollars.

### Gender distribution

The bias on the gender distribution (if any) when purchasing items in the store can be observed in Figure \@ref(fig:gender-distribution):  

```{r gender-distribution, fig.cap = "Amount paid per gender."}
# Gender distribution
transactions.ord %>% filter(total_amt>0) %>% 
    group_by(cust_age, Gender) %>% summarise(n = n()) %>% 
    ggplot(aes(cust_age, n, fill = Gender)) + 
           geom_bar(stat = "identity", color = "black", position = "dodge") +
           scale_y_continuous(breaks = seq(0, 600, 100), labels = number) +
           xlab("Customer Age") + ylab("Number of customers")


```
  


Figure \@ref(fig:gender-distribution) shows that here is some majority of sex in some ages (e.g. 32-33 years old), however it does not seem to be much big of a difference. The customer age range provided in the data comprises from 20-45 years old. Therefore, this is a signal of somehow a bias in the whole sample, since it does not capture teenagers nor 45+ people purchases. The latter ones can even have a significant purchasing power, but however, it is not available in the data provided.

### Average of amount spent over time 

Another important aspect to evaluate is the amount of money spent throughout the years and also to observe how much is spent each month, to observe if there are seasonality trends. The average amount spent each month per retail store is shown in Figure \@ref(fig:average-amount-spent-monthly):  



```{r average-amount-spent-monthly, fig.cap = "Average amount paid per store type."}
# Plot per month
transactions.ord %>% filter(total_amt > 0) %>%
                     mutate(year = year(tran_date), month = month(tran_date)) %>% 
                     ggplot(aes(as.factor(month), total_amt, fill = Store_type)) + 
                            geom_boxplot() +
                            scale_x_discrete(breaks = 1:12, 
                                               labels = c("Jan", "Feb", "Mar", 
                                                          "Apr", "May", "Jun", 
                                                          "Jul", "Aug", "Sep", 
                                                          "Oct", "Nov", "Dic"))+
                            xlab("Month") + 
                            ylab("Average Amount")
```
  


Figure \@ref(fig:average-amount-spent-yearly) shows the amount of money spent each year:  

```{r average-amount-spent-yearly, fig.cap = "Amount paid per category."}
# Plot per year
transactions.ord %>% filter(total_amt > 0) %>% 
                     mutate(year = year(tran_date), month = month(tran_date)) %>%
                     ggplot(aes(as.factor(year), total_amt, fill = prod_cat)) +
                            geom_boxplot() + 
                            xlab("Year") +
                            ylab("Average Amount")

```
  


Yearly expenditures appear to be quite stable over the years, as per Figure \@ref(fig:average-amount-spent-yearly). There is not a real trend of increasing or decreasing consistently over the years. Therefore, finding a time bias should be complicated.

We can also see the total amount of money spent in products yearly in Figure \@ref(fig:total-amount-spent-time):  

```{r total-amount-spent-time, fig.cap = "Total amount spent per product category each year."}
# See the amount of money spent per category per year 
transactions.ord %>% filter(total_amt > 0) %>% 
                     mutate(year = year(tran_date), month = month(tran_date)) %>%
                     group_by(prod_cat, year) %>% 
                     summarise(n = n(), total_amount = sum(total_amt)) %>%
                     ggplot(aes(x = year, y = total_amount, fill = prod_cat)) +
                            geom_bar(stat="identity", color = "black", 
                                     position = "dodge") + 
                            ylab("Total Amount Spent") + 
                            xlab("Year") +
                            scale_y_continuous(labels = number)
```
   
   
   
    


Figure \@ref(fig:total-amount-spent-time) shows significant differences between total amount of money spent per category. Therefore, the category could be a bias that could impact the amount of money to be spent. Let's see how people spends this money during the year in Figure \@ref(fig:total-amount-spent-monthly):  

```{r total-amount-spent-monthly, fig.cap = "Total amount spent per product category each month."}
# See the amount of money spent per category per month 
transactions.ord %>% filter(total_amt > 0) %>% 
                     mutate(year = year(tran_date), month = month(tran_date)) %>%
                     group_by(prod_cat, month) %>% 
                     summarise(n = n(), total_amount = sum(total_amt)) %>% 
                     ggplot(aes(x = month, y = total_amount, fill = prod_cat)) +
                            geom_bar(stat = "identity", color = "black", 
                                     position = "dodge") + 
                            ylab("Total Amount Spent") + 
                            xlab("Month") +
                            scale_x_continuous(breaks = 1:12, 
                                               labels = c("Jan", "Feb", "Mar", 
                                                          "Apr", "May", "Jun", 
                                                          "Jul", "Aug", "Sep", 
                                                          "Oct", "Nov", "Dic")) +
                            scale_y_continuous(breaks = seq(0, 1.5e6, 2.5e5), 
                                               labels = number)
```
  


There might be some seasonality in products such as books as seen in Figure \@ref(fig:total-amount-spent-monthly), when their sales spike in September and during the first months of the year (January-March).


### Amount of money spent per category at each age

Let's see in \@ref(fig:amount-spent-age) how much is spent per product category to observe is some products are more favored than others per age group.  



```{r amount-spent-age, fig.cap="Total amount spent per age."}

# Alternative plot by lines
transactions.ord %>% filter(total_amt>0) %>% 
                     group_by(cust_age, prod_cat) %>% 
                     summarise(n = n(), total_amount = sum(total_amt)) %>% 
                     ggplot(aes(x = cust_age, y = total_amount, color = prod_cat)) + 
                            geom_point() + geom_line() +
                            ylab("Total Amount Spent") + 
                            xlab("Customer Age") +
                            scale_y_continuous(labels = number) + 
                            scale_color_discrete(name = "Product Category")
```
  


As seen previously in Figure \@ref(fig:total-amount-spent-monthly), Figure \@ref(fig:amount-spent-age) also confirms that there are not big differences per age. Only a change of trend is seen in people of 32-33 years old who spend more money in home and kitchen than in books. This could be explained by the age they get married or have kids, resulting into moving to another house, with the subsequent increase in these costs.



### Users Histogram

One important aspect when considering a retail store is to know if our customers are normally new, or if they are recurrent. We can see this in Figure \@ref(fig:recurrent-users).  


```{r recurrent-users, fig.cap = "Number of times a user purchases in the store."}
summary.transactions <- transactions.ord %>% filter(total_amt>0) %>% 
                                             group_by(cust_id) %>% 
                                             summarise(n = n(), 
                                                       amount  = sum(total_amt))

avg_transaction <- mean(summary.transactions$amount)
avg_n_usr <- mean(summary.transactions$n)

summary.transactions %>% ggplot(aes(n)) + 
                                geom_histogram(binwidth = 1, 
                                               fill = "steelblue", 
                                               color = "black") + 
                                scale_x_continuous(breaks = 1:11) +
                                geom_vline(xintercept = avg_n_usr,  
                                           col = "maroon", 
                                           lty = 2, 
                                           lwd = 1) + 
                                xlab("Number of times a user repeats") + 
                                ylab("Number of users")
```
  


Figure \@ref(fig:recurrent-users) shows that customers return to the store within 4 years an average of `r avg_n_usr`.
It is also important to see how much money is each user spending in the store. We can see that in Figure \@ref(fig:amount-spent-users).  



```{r amount-spent-users, fig.cap = "Histogram of the total amount of money spent in the store"}
summary.transactions %>% ggplot(aes(amount)) + 
                                geom_histogram(bins = 30, 
                                               fill = "steelblue", 
                                               color = "black") +
                                # facet_wrap(~Gender) +  
                                # scale_x_continuous(breaks = 1:11) +
                                geom_vline(xintercept = avg_transaction,  
                                           col = "maroon", 
                                           lty = 2, 
                                           lwd = 1) + 
                                xlab("Amount spent by user") + 
                                ylab("Number of users") 
  
```
  


Even in the average that each user spends in the store is of `r round(avg_transaction, 0)`, we see in Figure \@ref(fig:amount-spent-users) that there are few users that spend over 30000. Is there any possibility to move the curve to the right?

\pagebreak

## **Model Development**

Looking at the data, we do not seem to see a particular bias over time or by city region or anything similar. If any, it appears to occur a bias on the group of the item.

We are going to try to attempt different regression models in order to predict the amount that a given customer can spend in the store

Let's first prepare the data by grouping the transactions by customer ID and collect the age, the city code, the gender and the total amount spent by the customer. Remember that for simplicity purposes, we are only using those transactions that are buys. 

We will use the data aggregated by customer for our predictions.

```{r prepare-rmse}
#Obtain the average amount
avg_amount <- mean(cust.desc$amount)

# Initialize the tibble
rmse_results <- tibble()
```

The average amount of the customer spent in our retail store is `r round(avg_amount, 0)` dollars.

### K-Nearest Neighbors

The first algorithm we are going to use is k-nearest neighbors, to try to evaluate a regression using as predictors the number of times going to the shop, the age and the city code. In order to be able to use k-nearest neighbors, we need to create dummy variables for the factors, and also to scale numerical variables between 0 and 1. Otherwise, the value of the variables has an impact in the prediction of the algorithm.

Therefore, let's create first the dummies and add it to the customer description data frame:

```{r prepare-dummy-knn}
# Prepare dummy variables for the k-nearest-neighbors
dms1 <- dummy("Gender", as.data.frame(cust.desc), sep = "_")
dms2 <- dummy("city_code", as.data.frame(cust.desc), sep = "_")
dms2 <- dms2[,-11]

#Explore that the number of the variables is the correct one
head(dms2)

# Create dummy variables needed for the k-nearest neighbors
cust.desc.dummies <- cbind(as.data.frame(cust.desc), dms1, dms2)
head(cust.desc.dummies)
```

Now, we need to re-scale the data to make sure that the age and the number of times going to the shop is re-scaled between 0 and 1

```{r rescale-data-knn}
# Scale the data for the K-Nearest Neighbors algorithm
cust.desc.dummies$age.s <- rescale(cust.desc.dummies$age)
cust.desc.dummies$n.s   <- rescale(cust.desc.dummies$n)
```

For k-nearest neighbors we are going to create a train set, a validation set and a test set. We will use 60% in our test set in this case. Let's use the caret package to do this:

```{r train-test-set-knn}
# We try now k-nearest neighbors
tr.id <- createDataPartition(cust.desc.dummies$amount, p = 0.6, list = F)
tr <- cust.desc.dummies[tr.id, ]
temp <- cust.desc.dummies[-tr.id, ]

v.id <- createDataPartition(temp$amount, p = 0.5, list = F)
val  <- temp[v.id, ]
test <- temp[-v.id, ]

```

Since K-nearest neighbors is an algorithm dependent on the value of k (the number of neighbors selected), we need to cover a range with that. Therefore, it is better to write two functions to handle this. We select columns 7 to 20 because they are the ones that include the Gender in dummy variables and also the city code. The results of the RMSE for different values of k is show in \@ref(fig:functions-knn).  

```{r functions-knn, fig.cap = "Result of RMSE for the k-nearest neighbors algorithm *on the validation set*  using the gender and the city as predictors."}
# Function to calculate the RMSE with a given K
func.knn.reg <- function(tr_predictor, val_predictor, 
                          tr_target, val_target, k){
  library(FNN)
  res <- knn.reg(tr_predictor, val_predictor, 
                 tr_target, k, algorithm = "brute")
  
  rmserror <- RMSE(res$pred, val_target)
  # cat(paste("RMSE for k = ", toString(k), ": ", rmserror, "\n", sep = ""))
  rmserror
}

# Function to calculate the RMSE with a given range of k's
func.knn.reg.multi <- function(tr_predictor, val_predictor, 
                                tr_target, val_target, 
                                start_k, end_k){
  rms_errors <- vector()
  for (k in start_k:end_k){
    rms_error <- func.knn.reg(tr_predictor, val_predictor, 
                               tr_target, val_target, k)
    rms_errors <- c(rms_errors, rms_error)
  }
  # Plot the error
  plot(rms_errors, type ='o', xlab = "k", ylab = "RMSE")
  return(rms_errors)
}

# Run the k-nearest neighbors for a big range
rmse.knn.gencity.val <- func.knn.reg.multi(tr[,7:20], val[,7:20], 
                                        tr$amount, val$amount, 1, 30)
```



The minimum RMSE using the k-neighbors with these predictors is `r min(rmse.knn.gencity.val)`. We will store it in the table using this code.

```{r, RMSE-knn-gencity-val}
# Collect RMSE results
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "K-Nearest Neighbors - City and Gender Predictors
                                 (Validation Set)",
                                 RMSE = min(rmse.knn.gencity.val)))

```

Let's do the same for the validation set to confirm that there is no overfitting. The results of the RMSE for different values of k is show in \@ref(fig:RMSE-knn-gencity-test).  

```{r, RMSE-knn-gencity-test, fig.cap = "Result of RMSE for the k-nearest neighbors algorithm *on the test set* using the gender and the city as predictors."}
# Run the k-nearest neighbors for a big range - for the test set
rmse.knn.gencity.test <- func.knn.reg.multi(tr[,7:20], val[,7:20], 
                                        tr$amount, val$amount, 1, 30)

# Collect RMSE results
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "K-Nearest Neighbors - City and Gender Predictors
                                 (Test Set)",
                                 RMSE = min(rmse.knn.gencity.test)))
```
  

The validation and the test set provide similar RMSE, which indicates no overfitting. However, the RMSE is very high, compared to the mean amount spent of `r avg_amount` dollars. Therefore, we should also consider the addition of some alternative predictors, such as the product category, which indicated some bias. We need to add the product category (the 6 major ones) and add them also as dummy variables. Let's prepare the data first following this code:

```{r prepare-data-knn-prod-cat, warning = F, message = F}
# Try to perform k-nearest neighbors adding the category and the year of the product
transactions.grouped <- transactions.ord %>% filter(total_amt > 0) %>% 
       group_by(cust_id) %>% select(cust_id, tran_date, prod_cat, total_amt) 

# Create dummies for the product category
dummy.transactions <- dummy.data.frame(as.data.frame(transactions.grouped), 
                                       names = "prod_cat", sep = " ")
colnames(dummy.transactions) <- str_remove(colnames(dummy.transactions), 
                                           "prod_cat ")
colnames(dummy.transactions) <- str_replace_all(colnames(dummy.transactions), "-", ".")
colnames(dummy.transactions) <- str_replace_all(colnames(dummy.transactions), " ", ".")

head(dummy.transactions)

# Group the dummy variables created by customer id
dummy.trans.grouped <- dummy.transactions %>%  group_by(cust_id) %>%      
                             summarise(n = n(), bags = sum(Bags), 
                                       Books = sum(Books), Clothing = sum(Clothing),
                                       Electronics = sum(Electronics),
                                       Footwear = sum(Footwear), 
                                       Home = sum(Home.and.kitchen))


# Add to the customer description data frame the dummy variables for the product category
final.cust <- cust.desc %>% left_join(dummy.trans.grouped, by = c("cust_id", "n"))
head(final.cust)

```

Once the new data is prepared as final customer data ("final.cust"), we need to create the dummy variables for k-nearest neighbors and scale the other numerical variables from 0 to 1.

```{r prepare-dummy-knn-v2, message = F, warning = F}
## Let's prepare the data again to apply K-nearest neighbors
dms3 <- dummy("Gender", as.data.frame(cust.desc), sep = "_")
dms4 <- dummy("city_code", as.data.frame(cust.desc), sep = "_")
dms4 <- dms4[,-11]

# Merge new dummy variables 
final.cust.dms <- cbind(as.data.frame(final.cust), dms3, dms4)

# Scale from 0 to 1 the other numerical variables
final.cust.dms$age.s <- rescale(final.cust.dms$age)
final.cust.dms$n.s   <- rescale(final.cust.dms$n)
```

Now we can attempt again k-nearest neighbors with our new predictors. We use the same distribution for validation, train and test set as before. The RMSE for the validation set is shown in Figure \@ref(train-val-prod-knn):  

```{r train-val-prod-knn, fig.cap = "Result of RMSE for the k-nearest neighbors algorithm *on the validation set* using the product category as predictor."}
# We try now k-nearest neighbors again
tr.id <- createDataPartition(final.cust.dms$amount, p = 0.6, list = F)
tr <- final.cust.dms[tr.id, ]
temp <- final.cust.dms[-tr.id, ]

v.id <- createDataPartition(temp$amount, p = 0.5, list = F)
val  <- temp[v.id, ]
test <- temp[-v.id, ]

# Try the K-Nearest Neighbors now
rmse.knn.prod.val <- func.knn.reg.multi(tr[,c(7:12)], val[,c(7:12)], 
                                        tr$amount, val$amount, 1, 30)

# Collect RMSE results
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "K-Nearest Neighbors - Product as Predictors 
                                 (Validation Set)",
                                 RMSE = min(rmse.knn.prod.val)))
```
  

It does appear to substantially from using the city and the gender. Let's try to attempt it on the test set to ensure that we are not overfitting the model. The RMSE for the test set is shown in Figure \@ref(train-test-prod-knn):  

```{r train-test-prod-knn, fig.cap = "Result of RMSE for the k-nearest neighbors algorithm *on the test set* using the product category as predictor."}
rmse.knn.prod.test <- func.knn.reg.multi(tr[,c(7:12)], test[,c(7:12)], 
                                        tr$amount, test$amount, 1, 30)

# Collect RMSE results
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "K-Nearest Neighbors - Product as Predictors 
                                 (Test Set)",
                                 RMSE = min(rmse.knn.prod.test)))
```
  

Looks like our K-nearest neighbors works much better when only considering the type of product and does not overfit.

The RMSE is on the test set is `r min(rmse.knn.prod.test)`, which is still somehow high considering what is the average amount. However, to see also how good might be the model, it is interesting to compare it with the Linear Regression 

### Linear Regression

Let's try the simplest model to compare how good or not is our k-nearest neighbors algorithm tested. For the linear method we will use a 70% train set and a 30% test set, since we will not use a validation one. Since the data does not require to be scaled, we will come back to the *final.cust* variable which does not contain dummy variables nor scaled ones,

```{r linear-regression}
# Create a train set
tr.id <- createDataPartition(final.cust$amount, p = 0.7, list = F)

# Ignore the first column because it is of no use
mod_lm <- lm(amount ~., data = final.cust[tr.id,-c(1,2)]) 

# see the linear model
summary(mod_lm)
rmse.linear <- sqrt(mean(as.matrix(mod_lm$fitted.values - 
                                   final.cust[-tr.id, "amount"])^2))


# Collect the results
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "Linear Mode (Test Set)",
                                 RMSE   = rmse.linear))
```

The summary of the data reveals the importance of the product category in our lineal model, as seen during the exploratory analysis. The RMSE is on the test set is `r min(rmse.linear)`, which is substantially higher (more than 75%) to the one obtained with the k-nearest neighbors.

Let's explore other algorithms to see how much we can improve our prediction.

### Random Trees

Let's try the random trees algorithm to see if it can be better or not than the k-nearest neighbors. From here onward, we will test the fitting on the model on the test set only. We will use again 70% for the test set and 30% for the test set. Let's plot the random trees
in \@ref(fig:random-trees):   

```{r random-trees, fig.cap="Plot of the random trees."}
### Random Forest or Random Trees for regression....
library(rpart)
library(rpart.plot)

tr.id <- createDataPartition(final.cust$amount, p = 0.7, list = F)

store.fit <- rpart(amount ~., data = final.cust[tr.id,-c(1,2)])
store.fit

# Plot the random trees fit with the rpart plot
prp(store.fit, type = 2, nn = T,
    fallen.leaves = T, faclen = 4,
    varlen = 8, shadow.col ="gray")

```
Once we see the tree plot, we can decide to prune the tree, in order to get less variables involved.

```{r random-trees-cutoff, fig.cap = "Cutoff point of the random trees"}
# The representation gives 10 trees as the adequate number
plotcp(store.fit)
```

Once we have found the threshold value, we can do the fitting with the trees pruned, for a simplified model.


```{r random-trees-plots, fig.cap = "Plot of the pruned trees"}
# See the cp table to get the first cp value below the cut-off point
store.fit$cptable

# Use the model of random trees with less branches for the new prediction
# Select tree below that value (10 in this case)
store.fitpruned <- prune(store.fit, cp = 0.01139806)

# Plot the new random trees pruned
prp(store.fitpruned, type = 2, nn = T,
    fallen.leaves = T, faclen = 4,
    varlen = 8, shadow.col ="gray")
```
Let's collect both predictions, for the non-pruned and the pruned random trees.


```{r random-trees-predictions}
# Obtain the predictions of the original random tree model
preds <- predict(store.fit, final.cust[-tr.id,-c(1,2)])
rmse.trees <- sqrt(mean(as.matrix(preds - final.cust[-tr.id, "amount"])^2))
rmse.trees

# Collect RMSE results
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "Random Trees  (Test Set)",
                                 RMSE = rmse.trees))

# Obtain the predictions of the pruned random tree model
preds <- predict(store.fitpruned, final.cust[-tr.id,-c(1,2)])
rmse.trees.pruned <- sqrt(mean(as.matrix(preds - final.cust[-tr.id, "amount"])^2))

# Collect RMSE results
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "Random Trees Pruned (Test Set)",
                                 RMSE = rmse.trees.pruned))


```

The random trees seem to yield worse results than K-Nearest Neighbors. However, There are two libraries that can enhance the predictions from random trees. They are the __ipred__ and the __gbm__ for bagging and boosting. Let's see the predictions obtained by using random trees from these two methods.

```{r random-trees-bagging-boosting}
# Let's use some techniques of bagging 
library(ipred)

# Fit the model with random trees with bagging
bagging.fit <- bagging(amount ~., data = final.cust[tr.id,-c(1,2)])
prediction.t <- predict(bagging.fit,  final.cust[-tr.id,-c(1,2)])

rmse.bagging <- sqrt(mean(as.matrix(prediction.t - final.cust[-tr.id, "amount"])^2))

# Collect RMSE results
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "Random Trees - Bagging (Test Set)",
                                 RMSE = rmse.bagging))
```

With Bagging the RMSE becomes smaller than using the random trees alone. Let's use some techniques of boosting.

```{r random-trees-boosting, warning= F, message = F}
library(gbm)

# Fit the model with random trees with boosting
gbm.fit <- gbm(amount ~., data = final.cust[tr.id,-c(1,2)], distribution = "gaussian")

# Obtain the prediction values over the test set
prediction.gbm <- predict(gbm.fit,  final.cust[-tr.id,-c(1,2)])
#Get the rmse on the test set
rmse.gbm <- sqrt(mean(as.matrix(prediction.gbm - final.cust[-tr.id, "amount"])^2))

# Collect RMSE results
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "Random Trees - Boosting (Test Set)",
                                 RMSE = rmse.gbm))

```

With Boosting, it becomes even better and quite close to the k-nearest neighbors result.

### Random Forests

Random trees by itself are okay, but they seem to be working well when using the bagging and the boosting methods. Let's try to use now a random forest. However, when using random forest, the previously data generated (final.cust) does not have sufficient predictors for the model to be executed.

Therefore, we revert into using the cust.desc.dummies data frame for the random forest model.

```{r random-forest}
mod.rf <- randomForest(x = cust.desc.dummies[tr.id,-c(1,2,6)], y = cust.desc.dummies[tr.id, 6],
                    ntree = 1000,
                    xtest = cust.desc.dummies[-tr.id,-c(1,2,6)],
                    ytest = cust.desc.dummies[-tr.id, "amount"],
                    importance = T, keep.forest = T)


# Obtain the prediction values over the test set
prediction.rf <- predict(mod.rf, cust.desc.dummies[-tr.id,-c(1,2,6)])

#Get the RMSE on the test set
rmse.rf <- sqrt(mean(as.matrix(prediction.rf - cust.desc.dummies[-tr.id, "amount"])^2))

# Collect RMSE results
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "Random Forest (Test Set)",
                                 RMSE = rmse.rf))


```

The random forest appears to be able to slightly improve the prediction of the k-nearest neighbors with products as predictors

### Neural Network

The last method to use is the use neural networks. Neural networks are a black box in terms of prediction. We know what it is going in and what it is going out, but not exactly how the model is working in between. We will use a source link from *fawda123* to visualize the neural network.

```{r neural-network, message = F, fig.cap = "Neural network plot to predict the amount spent in the retail store"}
library(nnet)
library(devtools)

# Get the maximum amount value to scale the neural network
max_amount <- max(final.cust$amount)

# Perform the fitting of the neural network
fit_nn <-nnet(amount/max_amount ~., data = final.cust[tr.id, -c(1,2)],
              size = 6, decay = 0.1,
              maxit = 1000, linout = T)

# Download source package to plot neural network
source_url("https://gist.githubusercontent.com/fawda123/7471137/raw/f30f338ecf143c089af1b6a731edcabd0b11a79d/nnet_plot_update.r")

#Plot the neural network
plot(fit_nn, max.sp = T)
 
# Compute RMSE over the training set
rmse.nn.tr <- sqrt(mean(as.matrix(fit_nn$fitted.values*max_amount - 
                                  final.cust[tr.id, "amount"])^2))


# Collect RMSE results
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "Neural Network (Train Set)",
                                 RMSE = rmse.nn.tr))

# Obtain the predictions over the test set
pred <- predict(fit_nn, final.cust[-tr.id,-c(1,2)])

# Compute RMSE over the test set
rmse.nn.test <- sqrt(mean(as.matrix(pred*max_amount - 
                                      final.cust[-tr.id, "amount"])^2, na.rm = T))

# Collect RMSE results
rmse_results <- bind_rows(rmse_results,
                          tibble(Method = "Neural Network (Test Set)",
                                 RMSE = rmse.nn.test))

```
\

The result provided by the neural network is the best we already saw from any product.

\pagebreak

## **Results**

Table \@ref(tab:results-table) contains the results of the RMSE on the train, the validation, and on the test set (when applicable):

```{r results-table}
knitr::kable(rmse_results, 
             caption = "RMSE results for the different methods",
             digits = 1, align = c('l','c')) %>%
             kableExtra::kable_styling(latex_options = "hold_position")
```

Table \@ref(tab:results-table) shows that the best method to predict the results is the `r rmse_results$Method[which.min(rmse_results$RMSE)]`. However, algorithms such a k-nearest neighbors with k = X or the random trees with the bagging appear also as a good options. 

Neural networks are kind of black boxes that do not allow the user to know what is really going inside them. For that reason, random trees might be preferred as they appear to be more transparent in the decision.

The RMSE seems somehow high for the target proposed. This might be due also to the quality of the data that seems already biased. No seasonality pattern is observed and not a significant difference between sex in terms of amount of money spent is observed. It is possible however that a better transformation of the data in a cluster could have been performed. In this case, the methods used for clustering (e.g. k-means) the customers ended up not giving any result and therefore, they were not shown.

## **Conclusions**

We have used a dataset of an online retail store. The data is somehow limited as it only comprises 2011-2014 and there is a narrow range of ages represented in this dataset (20-45 years old). The classification methods applied in order to cluster the users in some groups failed and therefore, we went directly to train the model in order to minimize the RMSE. 

The linear regression proved to be completely off the target. However, the use of other algorithms such as K-nearest neighbors, the random forests (particularly with the bagging) or the neural network managed to get much more accurate predictions on the amount a given customer is going to spend in the store.

### Limitations and future considerations

It has been a very challenging project all along, but the learning process was satisfactory. Personally, I would benefit of a little bit more time to finish the project as I started wrapping everything up too late (human nature). Some formalities in the final report could not be addressed due to issues with RMarkdown (e.g. numbering of captions disappearing).

The work on this data would benefit from the following approaches:
* Segmentation of users into clusters from a certain pattern 
* Transactions that include return could be added, and find a ratio between items purchased and returned by the customer
* The predictors could be used in all the categories instead of using only the main ones.
* The amount could be calculated per transaction, since the n has a big impact on the results.



